{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "## Walkthrough of Standard EDA Procedure\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEARNING OBJECTIVES\n",
    "\n",
    "\n",
    "### Core\n",
    "\n",
    "- Inspect the data with the `.describe()` method\n",
    "- Check for datatypes of different columns with `.dtypes`\n",
    "- Check for missing values with `.isnull`\n",
    "- Drop missing values with `.dropna`\n",
    "- Rename columns in a dataframe\n",
    "- Create boxplots, histograms and scatter plots from dataframe columns with seaborn\n",
    "- Standardize the data\n",
    "- Calculate the covariance and correlation between different columns in a dataframe\n",
    "- Create a heatmap of the correlations\n",
    "\n",
    "\n",
    "### Target\n",
    "- Understand the formulas for the the Pearson covariance/correlation\n",
    "- Know how to interpret covariance/correlation\n",
    "\n",
    "### Stretch\n",
    "- Understand the purpose of logarithmic axis scaling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Lesson Guide<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Walkthrough-of-Standard-EDA-Procedure\" data-toc-modified-id=\"Walkthrough-of-Standard-EDA-Procedure-1\">Walkthrough of Standard EDA Procedure</a></span></li><li><span><a href=\"#LEARNING-OBJECTIVES\" data-toc-modified-id=\"LEARNING-OBJECTIVES-2\">LEARNING OBJECTIVES</a></span><ul class=\"toc-item\"><li><span><a href=\"#Core\" data-toc-modified-id=\"Core-2.1\">Core</a></span></li><li><span><a href=\"#Target\" data-toc-modified-id=\"Target-2.2\">Target</a></span></li><li><span><a href=\"#Stretch\" data-toc-modified-id=\"Stretch-2.3\">Stretch</a></span></li><li><span><a href=\"#Description-of-the-Boston-Housing-Data-columns\" data-toc-modified-id=\"Description-of-the-Boston-Housing-Data-columns-2.4\">Description of the Boston Housing Data columns</a></span></li><li><span><a href=\"#Load-packages\" data-toc-modified-id=\"Load-packages-2.5\">Load packages</a></span></li><li><span><a href=\"#1.-Load-the-data\" data-toc-modified-id=\"1.-Load-the-data-2.6\">1. Load the data</a></span></li><li><span><a href=\"#2.-Look-at-the-first-few-lines-of-the-dataframe\" data-toc-modified-id=\"2.-Look-at-the-first-few-lines-of-the-dataframe-2.7\">2. Look at the first few lines of the dataframe</a></span></li><li><span><a href=\"#3.-Check-for-the-datatypes-of-each-column\" data-toc-modified-id=\"3.-Check-for-the-datatypes-of-each-column-2.8\">3. Check for the datatypes of each column</a></span></li><li><span><a href=\"#4.-Determine-how-many-observations-are-missing\" data-toc-modified-id=\"4.-Determine-how-many-observations-are-missing-2.9\">4. Determine how many observations are missing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Drop-the-null-values\" data-toc-modified-id=\"Drop-the-null-values-2.9.1\">Drop the null values</a></span></li></ul></li><li><span><a href=\"#5.-Make-the-column-names-more-descriptive\" data-toc-modified-id=\"5.-Make-the-column-names-more-descriptive-2.10\">5. Make the column names more descriptive</a></span></li><li><span><a href=\"#6.-Describe-the-summary-statistics-for-the-columns\" data-toc-modified-id=\"6.-Describe-the-summary-statistics-for-the-columns-2.11\">6. Describe the summary statistics for the columns</a></span></li><li><span><a href=\"#7.-Plot-variables-with-potential-outliers-using-boxplots\" data-toc-modified-id=\"7.-Plot-variables-with-potential-outliers-using-boxplots-2.12\">7. Plot variables with potential outliers using boxplots</a></span><ul class=\"toc-item\"><li><span><a href=\"#Produce-box-plots-for-a-few-more-of-the-variables\" data-toc-modified-id=\"Produce-box-plots-for-a-few-more-of-the-variables-2.12.1\">Produce box plots for a few more of the variables</a></span></li></ul></li><li><span><a href=\"#8.-Plot-all-the-variables-on-boxplots-together\" data-toc-modified-id=\"8.-Plot-all-the-variables-on-boxplots-together-2.13\">8. Plot all the variables on boxplots together</a></span></li><li><span><a href=\"#9.-Standardization-of-variables\" data-toc-modified-id=\"9.-Standardization-of-variables-2.14\">9. Standardization of variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pull-out-the-rate-of-crime-and-calculate-its-mean-and-standard-deviation\" data-toc-modified-id=\"Pull-out-the-rate-of-crime-and-calculate-its-mean-and-standard-deviation-2.14.1\">Pull out the <code>rate of crime</code> and calculate its mean and standard deviation</a></span></li><li><span><a href=\"#Standardize-the-rate_of_crime-variable\" data-toc-modified-id=\"Standardize-the-rate_of_crime-variable-2.14.2\">Standardize the rate_of_crime variable</a></span></li><li><span><a href=\"#Plot-the-original-and-standardized-rate-of-crime\" data-toc-modified-id=\"Plot-the-original-and-standardized-rate-of-crime-2.14.3\">Plot the original and standardized rate of crime</a></span></li><li><span><a href=\"#Plot-the-original-and-standardized-property-tax\" data-toc-modified-id=\"Plot-the-original-and-standardized-property-tax-2.14.4\">Plot the original and standardized property tax</a></span></li><li><span><a href=\"#Logarithmic-scaling\" data-toc-modified-id=\"Logarithmic-scaling-2.14.5\">Logarithmic scaling</a></span></li></ul></li><li><span><a href=\"#10.-Standardize-all-of-the-columns-and-re-create-the-boxplot\" data-toc-modified-id=\"10.-Standardize-all-of-the-columns-and-re-create-the-boxplot-2.15\">10. Standardize all of the columns and re-create the boxplot</a></span></li><li><span><a href=\"#11.-Covariance-and-correlation-matrices\" data-toc-modified-id=\"11.-Covariance-and-correlation-matrices-2.16\">11. Covariance and correlation matrices</a></span><ul class=\"toc-item\"><li><span><a href=\"#Covariance\" data-toc-modified-id=\"Covariance-2.16.1\">Covariance</a></span></li><li><span><a href=\"#Correlation\" data-toc-modified-id=\"Correlation-2.16.2\">Correlation</a></span></li><li><span><a href=\"#The-correlation-matrix\" data-toc-modified-id=\"The-correlation-matrix-2.16.3\">The correlation matrix</a></span></li><li><span><a href=\"#Compare-the-correlation-coefficients-for-the-whole-dataframe-before-(the-ones-just-calculated)-and-after-standardization\" data-toc-modified-id=\"Compare-the-correlation-coefficients-for-the-whole-dataframe-before-(the-ones-just-calculated)-and-after-standardization-2.16.4\">Compare the correlation coefficients for the whole dataframe before (the ones just calculated) and after standardization</a></span></li><li><span><a href=\"#Heatmap\" data-toc-modified-id=\"Heatmap-2.16.5\">Heatmap</a></span></li></ul></li><li><span><a href=\"#12.-Scatter-plots\" data-toc-modified-id=\"12.-Scatter-plots-2.17\">12. Scatter plots</a></span></li></ul></li><li><span><a href=\"#Independent-Practice:\" data-toc-modified-id=\"Independent-Practice:-3\">Independent Practice:</a></span></li><li><span><a href=\"#Optional-Practice:\" data-toc-modified-id=\"Optional-Practice:-4\">Optional Practice:</a></span></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-5\">Conclusions</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the Boston Housing Data columns\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This lesson uses a (famous) Boston housing market dataset to walk through a basic exploratory data analysis procedure, starting from the very beginning with loading the data. \n",
    "\n",
    "Though in many if not most cases the EDA procedure will be considerably more involved, this should give you an idea of the basic workflow a data scientist would go through when taking a look at a new dataset.\n",
    "\n",
    "> **Note:** This lesson is strictly exploratory. We will not be formulating any hypotheses about the data or testing them. In many cases you may have formulated a hypothesis before even looking at your data, which could considerably affect your focus and choices in what to investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the dataset have abbreviated names. The corresponding descriptions are:\n",
    "\n",
    "    CRIM: per capita crime rate by town \n",
    "    ZN: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "    INDUS: proportion of non-retail business acres per town \n",
    "    CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "    NOX: nitric oxides concentration (parts per 10 million) \n",
    "    RM: average number of rooms per dwelling \n",
    "    AGE: proportion of owner-occupied units built prior to 1940 \n",
    "    DIS: weighted distances to five Boston employment centres \n",
    "    RAD: index of accessibility to radial highways \n",
    "    TAX: full-value property-tax rate per 10000 dollars\n",
    "    PTRATIO: pupil-teacher ratio by town \n",
    "    B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "    LSTAT: % lower status of the population \n",
    "    MEDV: Median value of owner-occupied homes in 1000's of dollars\n",
    "    \n",
    "Each row in the dataset represents a different suburb of Boston.\n",
    "\n",
    "These descriptions of shortened or coded variables are often called **codebooks** or **data dictionaries**. They are typically found with datasets you might find online in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas & numpy libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pretty-print lib\n",
    "import pprint as pp\n",
    "\n",
    "# vis libs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "# \n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "---\n",
    "\n",
    "Import the csv into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn lib\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check type of data \n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data (how data looks like)\n",
    "pp.pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is dictionary-like with the following entries\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the stored data dictionary\n",
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check other keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the data in a data frame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check head \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (there is an extra column usually used as outcome variable in predictive modelling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check head again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Look at the first few lines of the dataframe\n",
    "---\n",
    "\n",
    "Use the `.head()` function (and optionally pass in an integer for the number of rows you want to see) to examine what the loaded data looks like. This is a good initial step to get a feeling for what is in the csv and what problems may be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the first 8 rows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check for the datatypes of each column\n",
    "\n",
    "The `.dtypes` attribute tells you the data type for each of your columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the dtypes of the columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Determine how many observations are missing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we start to build models with data, null values in observations are (almost) never allowed. It is important to always see how many observations are missing and for which columns.\n",
    "\n",
    "A handy way to look at how many null values there are per column with pandas is:\n",
    "\n",
    "```python\n",
    "boston.isnull().sum()\n",
    "```\n",
    "\n",
    "The `.isnull()` built-in function will convert the columns to boolean `True` and `False` values (returning a new dataframe) where null values are indicated by `True`. \n",
    "\n",
    "The `.sum()` function tacked on to the back of that will then sum these boolean columns, and the total number of null values per column will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the null values\n",
    "\n",
    "If there are missing values, to keep it simple one can just drop the rows from the dataset that contain null values. If a column has a ton of null values it often makes more sense to drop the column entirely instead of the rows with null values. \n",
    "\n",
    "The `.dropna()` function will drop any rows that have _**ANY**_ null values for you.  Use this carefully as you could drop many more rows than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape before droping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape after droping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make the column names more descriptive\n",
    "\n",
    "---\n",
    "\n",
    "Often it is annoying to have to memorize what the codes mean for columns, or reference the codebook whenever you want to know the meaning of a variable. It often makes sense to rename columns that are not descriptive.\n",
    "\n",
    "There is more than one way to do this, but one easy way is to use the `.rename()` function.\n",
    "\n",
    "Here are the column names and their descriptions again for reference:\n",
    "\n",
    "    CRIM: per capita crime rate by town \n",
    "    ZN: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "    INDUS: proportion of non-retail business acres per town \n",
    "    CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "    NOX: nitric oxides concentration (parts per 10 million) \n",
    "    RM: average number of rooms per dwelling \n",
    "    AGE: proportion of owner-occupied units built prior to 1940 \n",
    "    DIS: weighted distances to five Boston employment centres \n",
    "    RAD: index of accessibility to radial highways \n",
    "    TAX: full-value property-tax rate per 10000 dollars\n",
    "    PTRATIO: pupil-teacher ratio by town \n",
    "    B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "    LSTAT: % lower status of the population \n",
    "    MEDV: Median value of owner-occupied homes in 1000's of dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a list of column names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two popular methods to rename dataframe columns.\n",
    "1. Using a _dictionary substitution_, which is very useful if you only want to rename a few of the columns. This method uses the `.rename()` function.\n",
    "2. Using a _list replacement_, which is quicker than writing out a dictionary, but requires a full list of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 :List Replacement Method\n",
    "new_names = ['crime_rate',\n",
    "             'pct_res_zone',\n",
    "             'pct_buss_zone',\n",
    "             'boarders_river',\n",
    "             'conc_oxide',\n",
    "             'avg_rooms',\n",
    "             'pct_build_age',\n",
    "             'dist_to_work',\n",
    "             'highway_access',\n",
    "             'property_tax',\n",
    "             'student_teacher_ratio',\n",
    "             'black_stat',\n",
    "             'pct_underclass',\n",
    "             'med_home_value']\n",
    "boston.columns = new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data now \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "boston['MEDV'] = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 :Dictionary Method\n",
    "new_names_dict = {\n",
    "        'CRIM':'rate_of_crime',\n",
    "        'ZN':'residential_zone_pct',\n",
    "        'INDUS':'business_zone_pct',\n",
    "        'CHAS':'borders_river',\n",
    "        'NOX':'oxide_concentration',\n",
    "        'RM':'average_rooms',\n",
    "        'AGE':'owner_occup_pct',\n",
    "        'DIS':'dist_to_work',\n",
    "        'RAD':'access_to_highway',\n",
    "        'TAX':'property_tax',\n",
    "        'PTRATIO':'student_teacher_ratio',\n",
    "        'B':'black_stat',\n",
    "        'LSTAT':'pct_underclass',\n",
    "        'MEDV':'home_median_value'\n",
    "    }\n",
    "boston.rename(columns=new_names_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data now \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Describe the summary statistics for the columns\n",
    "\n",
    "---\n",
    "\n",
    "The `.describe()` function gives summary statistics for each of your variables. What are some, if any, oddities you notice about the variables based on this output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Plot variables with potential outliers using boxplots\n",
    "\n",
    "---\n",
    "\n",
    "Here we will use the seaborn package to plot boxplots of the variables we have identified as potentially having outliers.\n",
    "\n",
    "Some notes on seaborn's boxplot keyword argument options:\n",
    "\n",
    "    orient: can be 'v' or 'h' for vertical and horizontal, respectively\n",
    "    fliersize: the size of the outlier points (pixels I think)\n",
    "    linewidth: the width of the line around the box and up to the whiskers\n",
    "    notch: show the confidence interval for the median (calculated by seaborn/plt.boxplot)\n",
    "    saturation: saturate the colors to an extent\n",
    "    whis: extension of the whiskers in units of the interquartile range\n",
    "    ax: the axis object for the current figure\n",
    "\n",
    "    \n",
    "[Boxplots in seaborn](http://seaborn.pydata.org/generated/seaborn.boxplot.html)\n",
    "[Boxplots in matplotlib](http://matplotlib.org/api/pyplot_api.html?highlight=boxplot#matplotlib.pyplot.boxplot)\n",
    "\n",
    "_If you want to check out the documentation, place your cursor in the `boxplot` argument bracket and press `shift+tab` (press four times repeatedly to bring up detailed documentation)._\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot rate of crime\n",
    "\n",
    "#create fig\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "ax = fig.gca()\n",
    "\n",
    "# plot box plot\n",
    "sns.boxplot('rate_of_crime', data=boston, orient='v', fliersize=8, linewidth=1.5, ax=ax)\n",
    "\n",
    "# set title\n",
    "ax.set_title('Rate of crime boxplot', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Produce box plots for a few more of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Plot all the variables on boxplots together\n",
    "\n",
    "---\n",
    "\n",
    "Plot all the variables using using a horizontal boxplot with seaborn. What is wrong with this plot, if anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Standardization of variables\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescaling variables is very common, and sometimes essential. Many of the machine learning algorithms that we will be using require standardized data as input.\n",
    "\n",
    "Here we'll rescale the variables using a procedure called \"standardization\", which forces the distribution of each variable to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "Standardization is not complicated:\n",
    "\n",
    "    standardized_variable = (variable - mean_of_variable) / std_dev_of_variable\n",
    "\n",
    "The standardized variable is also often referred to as the **z-score** of the original variable. From the standardized variable it is easy to determine which data points are **outliers**. For example, one could say each observation with z-score larger than 3 or smaller than -3 would be more than three standard deviations away from the mean.\n",
    "    \n",
    "> **Note:** Nothing else is changed about the distribution of the variable. It does **not** become normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull out the `rate of crime` and calculate its mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check mean and Standard deviation before Standardization\n",
    "roc_mean = \n",
    "print(\"Mean: \", roc_mean)\n",
    "\n",
    "roc_std = \n",
    "print(\"Standard deviation: \", roc_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize the rate_of_crime variable\n",
    "\n",
    "> Notice the new mean is centered at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_standardized(var):\n",
    "    var_stand = (var-var.mean())/var.std()\n",
    "    return var_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do Standardization\n",
    "roc_stand = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check mean and Standard deviation after Standardization\n",
    "print(\"Mean: \", roc_stand.mean())\n",
    "print(\"Standard deviation: \", roc_stand.std())\n",
    "# not exactly a mean of 0 but excruciatingly close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the original rate of crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = fig.gca()\n",
    "\n",
    "sns.distplot(boston.rate_of_crime, bins=30, kde=False)\n",
    "ax.set_ylabel('counts\\n', fontsize=16)\n",
    "ax.set_title('Rate of crime distribution\\n', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the standardized rate of crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = fig.gca()\n",
    "\n",
    "sns.distplot(roc_stand, bins=30, kde=False)\n",
    "ax.set_ylabel('counts\\n', fontsize=16)\n",
    "ax.set_title('Standardised rate of crime distribution\\n', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the original and standardized property tax\n",
    "\n",
    "> Notice that nothing changes about the distribution except for the location and the scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# practice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Standardize all of the columns and re-create the boxplot\n",
    "\n",
    "---\n",
    "\n",
    "Pandas DataFrames make it extremely easy to standardize the columns all at once. You can standardize the data using\n",
    "\n",
    "```python\n",
    "boston_stand = (boston - boston.mean()) / boston.std()\n",
    "```\n",
    "\n",
    "Create a standardized version of the data and recreate the boxplot. Now you can better examine the differences in the shape of distributions across our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Correlation matrix\n",
    "\n",
    "We can see the correlation between all the numeric variables in our dataset by using pandas DataFrame's built in `.corr()` function on the whole dataframe. Use it below on the Boston dataset.\n",
    "\n",
    "It is very useful to get a feeling for what is related and what is not, which can help you decide what is worth investigating further (though with a lot of variables, the matrix can be a bit overwhelming...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the correlation coefficients for the whole dataframe before (the ones just calculated) and after standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap\n",
    "\n",
    "Seaborn also has a great way of showing this to us visually if colors stick out to you more than decimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 12. Scatter plots\n",
    "\n",
    "----\n",
    "\n",
    "Let's look at scatter plots for two variables that appear to be very related and two variables that appear to be unrelated.\n",
    "\n",
    "We can use seaborn's `regplot` to create a scatter plot between the pairs of variables. `regplot` will also plot a regression line by default â€“ we will go into regressions next week. They are, as you might expect, very related to correlations. You can turn this off with `fit_reg=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fig\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.gca()\n",
    "\n",
    "# scatter plot\n",
    "sns.regplot('business_zone_pct', 'pct_underclass', data=boston, fit_reg=True, \n",
    "                 color='steelblue', ax=ax)\n",
    "\n",
    "# set title\n",
    "ax.set_title('Business zone % vs underclass %')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Practice: \n",
    "\n",
    "* Create further scatter plots to explore relations between the different variables. Do you get any insight by plotting logarithmically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Practice:\n",
    "\n",
    "- Have a look at the [seaborn gallery](http://seaborn.pydata.org/examples/index.html) and explore when and how to use\n",
    "    - Pair plots\n",
    "    - Swarm plots\n",
    "    - Violin plots\n",
    "    - Joint plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this lesson we saw how to obtain useful information about the underlying data by using \n",
    "\n",
    "- boxplots\n",
    "- histograms\n",
    "- scatter plots\n",
    "- standardized variables\n",
    "- calculating the covariances/correlations among the variables. \n",
    "\n",
    "With these few tools we can already obtain important insight about any dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {
    "height": "305px",
    "width": "551px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Lesson Guide",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
